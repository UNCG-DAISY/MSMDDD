{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg19\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io,transform\n",
    "import os\n",
    "import sys\n",
    "model_name = 'VGGNet_RealSpam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=128\n",
    "x = np.load('../Images/SpamReal/spamreal_x%s.npy' % size)\n",
    "y = np.load('../Images/SpamReal/spamreal_y%s.npy' % size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "base = vgg19.VGG19(include_top=False, weights=None, classes=2, input_shape=(size,size,3), pooling='avg')\n",
    "temp = base.output\n",
    "temp = Dropout(0.5)(temp)\n",
    "predictions = Dense(2, activation= 'softmax')(temp)\n",
    "model = Model(inputs = base.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7872 samples, validate on 2625 samples\n",
      "Epoch 1/40\n",
      "7872/7872 [==============================] - 36s 5ms/step - loss: 0.6901 - acc: 0.5427 - val_loss: 0.6847 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68466, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 2/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6891 - acc: 0.5427 - val_loss: 0.6838 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68466 to 0.68378, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 3/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6884 - acc: 0.5427 - val_loss: 0.6823 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68378 to 0.68234, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 4/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6865 - acc: 0.5427 - val_loss: 0.6779 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68234 to 0.67790, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 5/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6785 - acc: 0.5414 - val_loss: 0.6565 - val_acc: 0.5611\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.67790 to 0.65647, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 6/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6626 - acc: 0.5644 - val_loss: 0.6195 - val_acc: 0.6282\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.65647 to 0.61950, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 7/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6717 - acc: 0.5403 - val_loss: 0.6892 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61950\n",
      "Epoch 8/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6863 - acc: 0.5427 - val_loss: 0.6868 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61950\n",
      "Epoch 9/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.6784 - acc: 0.5424 - val_loss: 0.6881 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61950\n",
      "Epoch 10/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.6621 - acc: 0.5426 - val_loss: 0.6908 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61950\n",
      "Epoch 11/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.6319 - acc: 0.6057 - val_loss: 0.5800 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61950 to 0.58001, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 12/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.5592 - acc: 0.7236 - val_loss: 0.5351 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58001 to 0.53506, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 13/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.5342 - acc: 0.7430 - val_loss: 0.6411 - val_acc: 0.6194\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53506\n",
      "Epoch 14/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.5103 - acc: 0.7588 - val_loss: 0.4618 - val_acc: 0.8053\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53506 to 0.46179, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 15/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4925 - acc: 0.7717 - val_loss: 0.5745 - val_acc: 0.6949\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.46179\n",
      "Epoch 16/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4764 - acc: 0.7801 - val_loss: 0.4164 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.46179 to 0.41637, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 17/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4638 - acc: 0.7866 - val_loss: 0.5020 - val_acc: 0.7627\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41637\n",
      "Epoch 18/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4490 - acc: 0.7942 - val_loss: 0.4071 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.41637 to 0.40709, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 19/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4317 - acc: 0.8102 - val_loss: 0.3882 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.40709 to 0.38824, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 20/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.4220 - acc: 0.8178 - val_loss: 0.3751 - val_acc: 0.8370\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38824 to 0.37509, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 21/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.3994 - acc: 0.8289 - val_loss: 0.3672 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.37509 to 0.36725, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 22/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3941 - acc: 0.8269 - val_loss: 0.3991 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.36725\n",
      "Epoch 23/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.3733 - acc: 0.8412 - val_loss: 0.3225 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.36725 to 0.32247, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 24/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3701 - acc: 0.8457 - val_loss: 0.3215 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.32247 to 0.32154, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 25/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3508 - acc: 0.8538 - val_loss: 0.3121 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.32154 to 0.31206, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 26/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3434 - acc: 0.8570 - val_loss: 0.3238 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.31206\n",
      "Epoch 27/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3372 - acc: 0.8603 - val_loss: 0.3102 - val_acc: 0.8766\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.31206 to 0.31018, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 28/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3274 - acc: 0.8666 - val_loss: 0.3051 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.31018 to 0.30514, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 29/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3224 - acc: 0.8692 - val_loss: 0.3024 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.30514 to 0.30236, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 30/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.3109 - acc: 0.8768 - val_loss: 0.2918 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.30236 to 0.29184, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 31/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3160 - acc: 0.8730 - val_loss: 0.2982 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.29184\n",
      "Epoch 32/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.3006 - acc: 0.8775 - val_loss: 0.3401 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.29184\n",
      "Epoch 33/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.2944 - acc: 0.8854 - val_loss: 0.4246 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.29184\n",
      "Epoch 34/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.2932 - acc: 0.8817 - val_loss: 0.2757 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.29184 to 0.27574, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 35/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.2897 - acc: 0.8833 - val_loss: 0.2979 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.27574\n",
      "Epoch 36/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.2917 - acc: 0.8827 - val_loss: 0.2753 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.27574 to 0.27529, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 37/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.2770 - acc: 0.8885 - val_loss: 0.2754 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.27529\n",
      "Epoch 38/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.2778 - acc: 0.8890 - val_loss: 0.2731 - val_acc: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 0.27529 to 0.27308, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 39/40\n",
      "7872/7872 [==============================] - 34s 4ms/step - loss: 0.2694 - acc: 0.8929 - val_loss: 0.2568 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.27308 to 0.25685, saving model to VGGNet_RealSpam.best.hdf5\n",
      "Epoch 40/40\n",
      "7872/7872 [==============================] - 35s 4ms/step - loss: 0.2670 - acc: 0.8928 - val_loss: 0.2484 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.25685 to 0.24836, saving model to VGGNet_RealSpam.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# rmsp = rmsprop(lr=0.01, decay=0.9, epsilon=1, clipvalue=2)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['acc'])\n",
    "\n",
    "filepath=\"%s.best.hdf5\" % model_name\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "hist = model.fit([x_train], y_train, batch_size=32, epochs=40, validation_data=([x_test], y_test), verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"%s.json\" % model_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# # serialize weights to HDF5\n",
    "model.save_weights(\"%s.h5\" % model_name)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block4_conv2/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@block4_conv2/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block4_conv2/kernel, block4_conv2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block4_conv2/kernel/Assign', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-99500cc65554>\", line 3, in <module>\n    base = vgg19.VGG19(include_top=False, weights=None, classes=2, input_shape=(size,size,3), pooling='avg')\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/applications/__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/applications/vgg19.py\", line 11, in VGG19\n    return vgg19.VGG19(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras_applications/vgg19.py\", line 157, in VGG19\n    name='block4_conv2')(x)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block4_conv2/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@block4_conv2/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block4_conv2/kernel, block4_conv2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block4_conv2/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@block4_conv2/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block4_conv2/kernel, block4_conv2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5975bc73172a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.h5\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded model from disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1056\u001b[0m                              ' elements.')\n\u001b[1;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block4_conv2/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@block4_conv2/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block4_conv2/kernel, block4_conv2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block4_conv2/kernel/Assign', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-99500cc65554>\", line 3, in <module>\n    base = vgg19.VGG19(include_top=False, weights=None, classes=2, input_shape=(size,size,3), pooling='avg')\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/applications/__init__.py\", line 28, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/applications/vgg19.py\", line 11, in VGG19\n    return vgg19.VGG19(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras_applications/vgg19.py\", line 157, in VGG19\n    name='block4_conv2')(x)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 431, in __call__\n    self.build(unpack_singleton(input_shapes))\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 141, in build\n    constraint=self.kernel_constraint)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\", line 252, in add_weight\n    constraint=constraint)\n  File \"/home/smsayeda/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block4_conv2/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@block4_conv2/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block4_conv2/kernel, block4_conv2/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('%s.json' % model_name, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"%s.h5\" % model_name)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import scikitplot as skplt\n",
    "%matplotlib inline\n",
    "\n",
    "predicted = model.predict([x_test])\n",
    "true = []\n",
    "pred = []\n",
    "for i in range(len(predicted)):\n",
    "    p_tmp = predicted[i][1]\n",
    "    t_tmp = np.argmax(y_test[i], -1)\n",
    "    pred.append(p_tmp)\n",
    "    true.append(t_tmp)\n",
    "pred = np.array(pred)\n",
    "true = np.array(true)\n",
    "skplt.metrics.plot_ks_statistic(np.array(true), list(zip(1-pred, pred)))\n",
    "\n",
    "print(\"precision_score: \", precision_score(true, pred>=0.488))\n",
    "print(\"recall_score: \", recall_score(true, pred>=0.488))\n",
    "print(\"f1_score: \", f1_score(true, pred>=0.488))\n",
    "print(\"roc_auc_score: \", roc_auc_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('%s.json' % model_name, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"%s.best.hdf5\" % model_name)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8844086021505376\n",
      "0.875\n",
      "0.8944138276553106\n",
      "0.8796791443850267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "predicted = model.predict([x_test])\n",
    "true = []\n",
    "pred = []\n",
    "for i in range(len(predicted)):\n",
    "    p_tmp = np.argmax(predicted[i], axis=-1)\n",
    "    t_tmp = np.argmax(y_test[i], -1)\n",
    "    pred.append(p_tmp)\n",
    "    true.append(t_tmp)\n",
    "\n",
    "print(precision_score(true, pred))\n",
    "print(recall_score(true, pred))\n",
    "print(roc_auc_score(true, pred))\n",
    "print(f1_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, _ = roc_curve(true, predicted[:,1])\n",
    "np.save('fpr_%s.npy' % model_name, fpr)\n",
    "np.save('tpr_%s.npy' % model_name, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
